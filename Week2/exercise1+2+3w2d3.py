# -*- coding: utf-8 -*-
"""Exercise1+2+3w2d3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fYyRCyVOaYANkcaANnKipxyDS86WqDWn
"""

from google.colab import files
files.upload()

import pandas as pd

train_data = pd.read_csv("train.csv")

train_data.duplicated()

train_data.drop_duplicates()

"""No duplicates were found"""

# Check for missing values in a DataFrame
df = pd.DataFrame(train_data)
missing_data = df.isnull()

print(missing_data.head())

# Count missing values in each column
missing_counts = df.isnull().sum()
print(missing_counts)

# Remove raws with missing values
df_cleaned = df.dropna()
print (df_cleaned.head())

# Remove columns with missing values
df_cleaned = df.dropna(axis=1)
print (df_cleaned)

# Fill missing values with a specific value (e.g., 0)
df_filled = df.fillna(0)
print (df_filled.head())

# Create Family Size feature
FamilySize = df["SibSp"] + df["Parch"]
print (FamilySize)

Title = df["Name"].str.extract(r' ([A-Za-z]+)')
print (Title)

df["FamilySize"] = df["SibSp"] + df["Parch"] + 1
print(df.head())

print(df[["SibSp", "Parch", "FamilySize"]].head())

print(df.columns)

df["Title"] = df["Name"].str.extract(r' ([A-Za-z]+)\.', expand=False)

df["Sex_male"] = df["Sex_male"].astype(str)
df["Embarked_Q"] = df["Embarked_Q"].astype(str)

# convert categorical variables into numerical form using one-hot encoding or label encoding.
df = pd.get_dummies(df, columns=["Sex_male", "Embarked_Q", "Title"], drop_first=True)

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
df["Pclass"] = encoder.fit_transform(df["Pclass"])  # Example (not needed for Pclass)

print(df.head())

# Standardization
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[["Age", "Fare", "FamilySize"]] = scaler.fit_transform(df[["Age", "Fare", "FamilySize"]])

# Normalization
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
df[["Age", "Fare", "FamilySize"]] = scaler.fit_transform(df[["Age", "Fare", "FamilySize"]])

print(df.describe())

import numpy as np

# to detect outliers in columns
Q1 = train_data['Age'].quantile(0.25)

Q3 = train_data['Age'].quantile(0.75)

IQR = Q3 - Q1

print (IQR)

lower_bound = Q1 - 1.5 * IQR
print (lower_bound)

upper_bound = Q3 + 1.5 * IQR
print (upper_bound)

# "trimming" or "outlier removal."
outliers = train_data[(train_data['Age'] >= lower_bound) & (train_data['Age'] <= upper_bound)]

print (outliers)

# Summary statistics before and after capping
print("Before Handling Outliers:")
print(train_data.describe())

print("\nAfter Handling Outliers:")
print(train_data.describe())

print(f"Age Lower Bound: {lower_bound}, Upper Bound: {upper_bound}")

# Exercise5 # Assess the scale and distribution of numerical columns in the dataset.
print(train_data.describe())

# Fare is heavily skewed with extreme outliers. You should consider:
# Log transformation
np.log1p(train_data['Fare'])

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.histplot(train_data['Fare'], bins=50, kde=True)
plt.title("Fare Distribution (Before Log Transformation)")

# After transformation
plt.subplot(1, 2, 2)
sns.histplot(np.log1p(train_data['Fare']), bins=50, kde=True)
plt.title("Fare Distribution (After Log Transformation)")

plt.show()

# replace the original Fare column with the transformed version:
train_data['Fare'] = np.log1p(train_data['Fare'])

train_data.describe()

